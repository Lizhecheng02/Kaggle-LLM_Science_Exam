{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c1c782-dfff-4358-ab38-28011f05d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa00f0e-0e46-4223-9115-9c7a75353adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path: ./Raw Dataset/99k new dataset\\RACE_0_6000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_12000_18000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_18000_24000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_24000_30000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_30000_36000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_36000_42000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_42000_48000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_48000_54000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_54000_60000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_60000_66000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_6000_12000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_66000_72000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_72000_78000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_78000_84000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_84000_90000.json\n",
      "file path: ./Raw Dataset/99k new dataset\\RACE_90000_end.json\n",
      "(97687, 8)\n",
      "answer\n",
      "B    19677\n",
      "C    19621\n",
      "D    19559\n",
      "E    19450\n",
      "A    19380\n",
      "Name: count, dtype: int64\n",
      "(0, 8)\n",
      "(80134, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(\"./Raw Dataset/99k new dataset\"):\n",
    "    if file_name.startswith(\"RACE\"):\n",
    "        print(\"file path:\", os.path.join(\"./Raw Dataset/99k new dataset\", file_name))\n",
    "        tmp_df = pd.read_json(os.path.join(\"./Raw Dataset/99k new dataset\", file_name))\n",
    "        df = pd.concat([df, tmp_df])\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df_shuffle = df.copy()\n",
    "\n",
    "def shuffle_answer(idx):\n",
    "    try:\n",
    "        tmp = ['A', 'B', 'C', 'D', 'E']\n",
    "        random.shuffle(tmp)\n",
    "        hm = {k: v for k, v in zip(['A', 'B', 'C', 'D', 'E'], tmp)}\n",
    "        hm_b = {v: k for k, v in zip(['A', 'B', 'C', 'D', 'E'], tmp)}\n",
    "        df_shuffle.loc[idx, ['A', 'B', 'C', 'D', 'E']] = [\n",
    "            df.loc[idx, hm[k]] for k in ['A', 'B', 'C', 'D', 'E']]\n",
    "        df_shuffle.loc[idx, 'answer'] = hm_b[df.loc[idx, 'answer']]\n",
    "    except:\n",
    "        print(\"Error!\")\n",
    "\n",
    "\n",
    "for i in range(len(df_shuffle)):\n",
    "    shuffle_answer(i)\n",
    "\n",
    "df = df_shuffle.copy()\n",
    "print(df[\"answer\"].value_counts())\n",
    "\n",
    "df_with_nan = df[df.isna().any(axis=1)]\n",
    "print(df_with_nan.shape)\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"prompt\"])\n",
    "print(df.shape)\n",
    "\n",
    "def clean_string(s):\n",
    "    text = re.sub(r'#+', '', s)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'\\(\\)', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"context\"] = df[\"context\"].apply(clean_string)\n",
    "\n",
    "df.to_json(\"./Clean Dataset/Race no #.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedf6b4b-0533-47ba-849b-301c1a98ee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path: ./Raw Dataset/99k new dataset\\TruthQA.json\n",
      "(817, 8)\n",
      "answer\n",
      "C    170\n",
      "B    166\n",
      "A    162\n",
      "D    160\n",
      "E    159\n",
      "Name: count, dtype: int64\n",
      "(0, 8)\n",
      "(817, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(\"./Raw Dataset/99k new dataset\"):\n",
    "    if file_name.startswith(\"Truth\"):\n",
    "        print(\"file path:\", os.path.join(\"./Raw Dataset/99k new dataset\", file_name))\n",
    "        tmp_df = pd.read_json(os.path.join(\"./Raw Dataset/99k new dataset\", file_name))\n",
    "        df = pd.concat([df, tmp_df])\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df_shuffle = df.copy()\n",
    "\n",
    "def shuffle_answer(idx):\n",
    "    try:\n",
    "        tmp = ['A', 'B', 'C', 'D', 'E']\n",
    "        random.shuffle(tmp)\n",
    "        hm = {k: v for k, v in zip(['A', 'B', 'C', 'D', 'E'], tmp)}\n",
    "        hm_b = {v: k for k, v in zip(['A', 'B', 'C', 'D', 'E'], tmp)}\n",
    "        df_shuffle.loc[idx, ['A', 'B', 'C', 'D', 'E']] = [\n",
    "            df.loc[idx, hm[k]] for k in ['A', 'B', 'C', 'D', 'E']]\n",
    "        df_shuffle.loc[idx, 'answer'] = hm_b[df.loc[idx, 'answer']]\n",
    "    except:\n",
    "        print(\"Error!\")\n",
    "\n",
    "\n",
    "for i in range(len(df_shuffle)):\n",
    "    shuffle_answer(i)\n",
    "\n",
    "df = df_shuffle.copy()\n",
    "print(df[\"answer\"].value_counts())\n",
    "\n",
    "df_with_nan = df[df.isna().any(axis=1)]\n",
    "print(df_with_nan.shape)\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"prompt\"])\n",
    "print(df.shape)\n",
    "\n",
    "def clean_string(s):\n",
    "    text = re.sub(r'#+', '', s)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'\\(\\)', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"context\"] = df[\"context\"].apply(clean_string)\n",
    "\n",
    "df.to_json(\"./Clean Dataset/TruthQA no #.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4707cb09-0c6d-43c4-b0bb-61eccf04b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path: ./Raw Dataset/99k new dataset\\valid_500.json\n",
      "(500, 8)\n",
      "answer\n",
      "B    111\n",
      "D    105\n",
      "C     96\n",
      "E     96\n",
      "A     92\n",
      "Name: count, dtype: int64\n",
      "(0, 8)\n",
      "(499, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(\"./Raw Dataset/99k new dataset\"):\n",
    "    if file_name.startswith(\"valid\"):\n",
    "        print(\"file path:\", os.path.join(\"./Raw Dataset/99k new dataset\", file_name))\n",
    "        tmp_df = pd.read_json(os.path.join(\"./Raw Dataset/99k new dataset\", file_name))\n",
    "        df = pd.concat([df, tmp_df])\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df_shuffle = df.copy()\n",
    "\n",
    "def shuffle_answer(idx):\n",
    "    try:\n",
    "        tmp = ['A', 'B', 'C', 'D', 'E']\n",
    "        random.shuffle(tmp)\n",
    "        hm = {k: v for k, v in zip(['A', 'B', 'C', 'D', 'E'], tmp)}\n",
    "        hm_b = {v: k for k, v in zip(['A', 'B', 'C', 'D', 'E'], tmp)}\n",
    "        df_shuffle.loc[idx, ['A', 'B', 'C', 'D', 'E']] = [\n",
    "            df.loc[idx, hm[k]] for k in ['A', 'B', 'C', 'D', 'E']]\n",
    "        df_shuffle.loc[idx, 'answer'] = hm_b[df.loc[idx, 'answer']]\n",
    "    except:\n",
    "        print(\"Error!\")\n",
    "\n",
    "\n",
    "for i in range(len(df_shuffle)):\n",
    "    shuffle_answer(i)\n",
    "\n",
    "df = df_shuffle.copy()\n",
    "print(df[\"answer\"].value_counts())\n",
    "\n",
    "df_with_nan = df[df.isna().any(axis=1)]\n",
    "print(df_with_nan.shape)\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"prompt\"])\n",
    "print(df.shape)\n",
    "\n",
    "def clean_string(s):\n",
    "    text = re.sub(r'#+', '', s)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'\\(\\)', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"context\"] = df[\"context\"].apply(clean_string)\n",
    "\n",
    "df.to_json(\"./Clean Dataset/valid_500 no #.json\", orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
