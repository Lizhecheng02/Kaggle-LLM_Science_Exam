{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa74635",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-10T11:27:23.221277Z",
     "iopub.status.busy": "2023-09-10T11:27:23.220609Z",
     "iopub.status.idle": "2023-09-10T11:27:47.356975Z",
     "shell.execute_reply": "2023-09-10T11:27:47.355745Z"
    },
    "papermill": {
     "duration": 24.144547,
     "end_time": "2023-09-10T11:27:47.359488",
     "exception": false,
     "start_time": "2023-09-10T11:27:23.214941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\r\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\r\n",
      "Successfully installed faiss-cpu-1.7.4\r\n",
      "Collecting sentence_transformers\r\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.30.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.65.0)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0+cpu)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1+cpu)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.1)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.16.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.6.3)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\r\n",
      "Building wheels for collected packages: sentence_transformers\r\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=b31098cb833a5866a70f6dbd4404ab39d83c14cb4969347c3d9040cff60a1a73\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\r\n",
      "Successfully built sentence_transformers\r\n",
      "Installing collected packages: sentence_transformers\r\n",
      "Successfully installed sentence_transformers-2.2.2\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install faiss-gpu\n",
    "!pip install faiss-cpu\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d72f25c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T11:27:47.371824Z",
     "iopub.status.busy": "2023-09-10T11:27:47.371441Z",
     "iopub.status.idle": "2023-09-10T11:27:55.534308Z",
     "shell.execute_reply": "2023-09-10T11:27:55.533191Z"
    },
    "papermill": {
     "duration": 8.171804,
     "end_time": "2023-09-10T11:27:55.536849",
     "exception": false,
     "start_time": "2023-09-10T11:27:47.365045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835902ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T11:27:55.549211Z",
     "iopub.status.busy": "2023-09-10T11:27:55.548564Z",
     "iopub.status.idle": "2023-09-10T11:27:55.554374Z",
     "shell.execute_reply": "2023-09-10T11:27:55.553118Z"
    },
    "papermill": {
     "duration": 0.014676,
     "end_time": "2023-09-10T11:27:55.556954",
     "exception": false,
     "start_time": "2023-09-10T11:27:55.542278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# index_folder = \"/kaggle/input/wikipedia-faiss-index\"\n",
    "\n",
    "# for idx, indexname in enumerate(os.listdir(index_folder)):\n",
    "#     index = faiss.read_index(os.path.join(index_folder, indexname))\n",
    "#     faiss.write_index(index, os.path.join(\"/kaggle/working/\", indexname))\n",
    "#     print(f\"Successfullt move the {indexname} from Input to Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5690506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T11:27:55.569631Z",
     "iopub.status.busy": "2023-09-10T11:27:55.569259Z",
     "iopub.status.idle": "2023-09-10T11:27:55.575651Z",
     "shell.execute_reply": "2023-09-10T11:27:55.574145Z"
    },
    "papermill": {
     "duration": 0.015638,
     "end_time": "2023-09-10T11:27:55.578056",
     "exception": false,
     "start_time": "2023-09-10T11:27:55.562418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_name = \"thenlper/gte-small\"\n",
    "# sentence_transformer = SentenceTransformer(model_name)\n",
    "# parquet_folder = \"/kaggle/input/wikipedia-20230701\"\n",
    "\n",
    "# file_names = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'number', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# for idx, filename in enumerate(file_names):\n",
    "#     if (idx + 1) >= 22:\n",
    "#         document_embeddings = []\n",
    "\n",
    "#         print(f\"Processing file_id: {idx + 1} - file_name: {filename}.parquet ......\")\n",
    "\n",
    "#         parquet_path = os.path.join(parquet_folder, f\"{filename}.parquet\")\n",
    "#         df = pd.read_parquet(parquet_path)\n",
    "\n",
    "#         print(df.columns)\n",
    "#         print(\"Sample text: \", df.iloc[0][\"text\"])\n",
    "\n",
    "#         sentences = df[\"text\"].tolist()\n",
    "#         embeddings = sentence_transformer.encode(sentences, normalize_embeddings=True)\n",
    "#         document_embeddings.extend(embeddings)\n",
    "\n",
    "#         del df\n",
    "\n",
    "#         document_embeddings = np.array(document_embeddings).astype(\"float32\")\n",
    "#         index = faiss.IndexFlatIP(document_embeddings.shape[1])\n",
    "#         index.add(document_embeddings)\n",
    "#         faiss_index_path = f\"/kaggle/working/wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         faiss.write_index(index, faiss_index_path)\n",
    "\n",
    "\n",
    "#         print(f\"Faiss index saved to '{faiss_index_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a01fe60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T11:27:55.590771Z",
     "iopub.status.busy": "2023-09-10T11:27:55.590165Z",
     "iopub.status.idle": "2023-09-10T11:27:55.598762Z",
     "shell.execute_reply": "2023-09-10T11:27:55.597365Z"
    },
    "papermill": {
     "duration": 0.017842,
     "end_time": "2023-09-10T11:27:55.601263",
     "exception": false,
     "start_time": "2023-09-10T11:27:55.583421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# index_folder1 = \"/kaggle/input/wikipedia-faiss-index\"\n",
    "# index_folder2 = \"/kaggle/input/wikipedia-faiss-index\"\n",
    "\n",
    "# file_names = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'number', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# merged_index = faiss.IndexFlatL2(384)\n",
    "# for idx, filename in enumerate(file_names):\n",
    "#     if (idx + 1) >= 7:\n",
    "#         break\n",
    "    \n",
    "#     if (idx + 1) >= 12 and (idx + 1) <= 20:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder2, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     else:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder1, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     if (idx + 1) == 6:\n",
    "#         merged_index_path = \"/kaggle/working/merged_1.index\"\n",
    "#         faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "#         print(f\"Merged index saved to '{merged_index_path}'\")\n",
    "        \n",
    "#         del merged_index\n",
    "\n",
    "        \n",
    "# merged_index = faiss.IndexFlatL2(384)\n",
    "# for idx, filename in enumerate(file_names):\n",
    "#     if (idx + 1) <= 6:\n",
    "#         continue\n",
    "        \n",
    "#     if (idx + 1) == 13:\n",
    "#         break\n",
    "    \n",
    "#     if (idx + 1) >= 12 and (idx + 1) <= 20:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder2, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     else:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder1, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     if (idx + 1) == 12:\n",
    "#         merged_index_path = \"/kaggle/working/merged_2.index\"\n",
    "#         faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "#         print(f\"Merged index saved to '{merged_index_path}'\")\n",
    "        \n",
    "#         del merged_index\n",
    "\n",
    "        \n",
    "# merged_index = faiss.IndexFlatL2(384)\n",
    "# for idx, filename in enumerate(file_names):\n",
    "#     if (idx + 1) <= 12:\n",
    "#         continue\n",
    "        \n",
    "#     if (idx + 1) == 20:\n",
    "#         break\n",
    "    \n",
    "#     if (idx + 1) >= 12 and (idx + 1) <= 20:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder2, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     else:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder1, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     if (idx + 1) == 19:\n",
    "#         merged_index_path = \"/kaggle/working/merged_3.index\"\n",
    "#         faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "#         print(f\"Merged index saved to '{merged_index_path}'\")\n",
    "        \n",
    "#         del merged_index\n",
    "        \n",
    "# merged_index = faiss.IndexFlatL2(384)\n",
    "# for idx, filename in enumerate(file_names):\n",
    "#     if (idx + 1) <= 19:\n",
    "#         continue\n",
    "    \n",
    "#     if (idx + 1) >= 12 and (idx + 1) <= 20:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder2, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     else:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder1, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     if (idx + 1) == 28:\n",
    "#         merged_index_path = \"/kaggle/working/merged_4.index\"\n",
    "#         faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "#         print(f\"Merged index saved to '{merged_index_path}'\")\n",
    "        \n",
    "#         del merged_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f568376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T11:27:55.613997Z",
     "iopub.status.busy": "2023-09-10T11:27:55.613276Z",
     "iopub.status.idle": "2023-09-10T11:30:30.761493Z",
     "shell.execute_reply": "2023-09-10T11:30:30.758880Z"
    },
    "papermill": {
     "duration": 155.161988,
     "end_time": "2023-09-10T11:30:30.768688",
     "exception": false,
     "start_time": "2023-09-10T11:27:55.606700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge file 1 - merged_1.index\n",
      "Merge file 2 - merged_2.index\n",
      "Merge file 3 - merged_3.index\n",
      "Merge file 4 - merged_4.index\n",
      "Merged index saved to '/kaggle/working/merged.index'\n"
     ]
    }
   ],
   "source": [
    "merged_index = faiss.IndexFlatL2(384)\n",
    "# merged_index = faiss.read_index(\"/kaggle/input/wikipedia-embeddings/merged_1.index\")\n",
    "index_folder = \"/kaggle/input/wikipedia-faiss-index\"\n",
    "\n",
    "for idx, indexname in enumerate(os.listdir(index_folder)):\n",
    "    print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "    index = faiss.read_index(os.path.join(index_folder, indexname))\n",
    "\n",
    "    num_vectors = index.ntotal\n",
    "    for i in range(num_vectors):\n",
    "        vec = index.reconstruct(i).reshape(-1, 384)\n",
    "        vec = np.array(vec).astype(\"float32\")\n",
    "        merged_index.add(vec)\n",
    "\n",
    "    del index\n",
    "\n",
    "merged_index_path = \"/kaggle/working/merged.index\"\n",
    "faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "print(f\"Merged index saved to '{merged_index_path}'\")"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 200.609926,
   "end_time": "2023-09-10T11:30:33.864826",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-10T11:27:13.254900",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
